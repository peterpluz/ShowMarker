import Foundation
import AVFoundation
import Combine

@MainActor
final class TimelineViewModel: ObservableObject {

    private let repository: ProjectRepository
    private let timelineID: UUID

    private let audioPlayer = AudioPlayerService()

    // MARK: - Published State (Only ViewModel-specific data)

    @Published private(set) var isPlaying: Bool = false
    @Published private(set) var currentTime: Double = 0
    @Published private(set) var duration: Double = 0

    @Published var zoomScale: CGFloat = 1.0

    @Published private(set) var cachedWaveform: [Float] = []
    private var waveformMipmaps: [[Float]] = []
    private var waveformCacheKey: String?

    // MARK: - Marker Crossing Detection

    // Event stream for marker flash events
    // Using PassthroughSubject ensures EVERY event is delivered to ALL subscribers
    // Unlike @Published Dictionary which can batch/coalesce rapid updates
    struct MarkerFlashEvent: Equatable {
        let markerID: UUID
        let markerName: String
        let eventID: Int
        let timestamp: Date
    }

    let markerFlashPublisher = PassthroughSubject<MarkerFlashEvent, Never>()
    private var flashCounter: Int = 0
    private var previousFrame: Int = -1
    private var triggeredMarkers: Set<UUID> = []  // Track which markers have flashed in current playback session

    // MARK: - Marker Drag State

    // Tracks which marker is being dragged and its preview time
    @Published var draggedMarkerID: UUID?
    @Published var draggedMarkerPreviewTime: Double?

    private var cancellables = Set<AnyCancellable>()

    // MARK: - Computed Properties (Single Source of Truth from Repository)

    var timeline: Timeline? {
        repository.project.timelines.first(where: { $0.id == timelineID })
    }

    var name: String {
        timeline?.name ?? ""
    }

    var fps: Int {
        timeline?.fps ?? 30
    }

    var audio: TimelineAudio? {
        timeline?.audio
    }

    var markers: [TimelineMarker] {
        (timeline?.markers ?? []).sorted { $0.timeSeconds < $1.timeSeconds }
    }
    
    // MARK: - Computed
    
    var visibleMarkers: [TimelineMarker] {
        markers
    }
    
    var visibleWaveform: [Float] {
        guard !waveformMipmaps.isEmpty else { return [] }

        // Use immediate zoom scale for visual synchronization (not debounced)
        let mipmapLevel = selectMipmapLevel(for: zoomScale)

        guard mipmapLevel < waveformMipmaps.count else {
            return waveformMipmaps.first ?? []
        }

        return waveformMipmaps[mipmapLevel]
    }

    private func selectMipmapLevel(for zoom: CGFloat) -> Int {
        // Choose mipmap level based on zoom:
        // Level 0: highest detail (zoom >= 10x)
        // Level 1: high detail (zoom >= 5x)
        // Level 2: medium detail (zoom >= 2x)
        // Level 3+: low detail (zoom < 2x)

        switch zoom {
        case 10...:
            return 0  // Maximum detail
        case 5..<10:
            return min(1, waveformMipmaps.count - 1)
        case 2..<5:
            return min(2, waveformMipmaps.count - 1)
        default:
            return min(3, waveformMipmaps.count - 1)  // Lowest detail
        }
    }
    
    // MARK: - Init

    init(repository: ProjectRepository, timelineID: UUID) {
        self.repository = repository
        self.timelineID = timelineID

        setupBindings()
        setupRepositoryObserver()

        // Load initial audio and duration from timeline
        if let timelineAudio = timeline?.audio, let docURL = repository.documentURL {
            self.duration = timelineAudio.duration

            // ‚úÖ CRITICAL FIX: Load audio into player on initialization
            let audioURL = docURL.appendingPathComponent(timelineAudio.relativePath)
            audioPlayer.load(url: audioURL)
            print("‚úÖ Audio loaded into player on init: \(audioURL)")

            loadWaveformCache(for: timelineAudio, documentURL: docURL)
        }
    }

    private func setupRepositoryObserver() {
        // Subscribe to repository changes to trigger UI updates
        repository.objectWillChange
            .receive(on: RunLoop.main)
            .sink { [weak self] _ in
                self?.objectWillChange.send()
            }
            .store(in: &cancellables)
    }
    
    private func setupBindings() {
        audioPlayer.$isPlaying
            .assign(to: &$isPlaying)

        // ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –£–±—Ä–∞–Ω throttle –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è "—Å–ª–µ–ø—ã—Ö –∑–æ–Ω" –≤ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Ä–∫–µ—Ä–æ–≤
        // AVPlayer —É–∂–µ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º ~33ms, throttle —Ç–æ–ª—å–∫–æ —Å–æ–∑–¥–∞–≤–∞–ª –ø—Ä–æ–ø—É—Å–∫–∏
        audioPlayer.$currentTime
            .receive(on: DispatchQueue.main)
            .assign(to: &$currentTime)

        audioPlayer.$duration
            .sink { [weak self] d in
                if d > 0 {
                    self?.duration = d
                }
            }
            .store(in: &cancellables)
        
        // Reset triggered markers when playback stops
        audioPlayer.$isPlaying
            .sink { [weak self] isPlaying in
                guard let self = self else { return }
                if !isPlaying {
                    // When playback stops, clear all triggered markers
                    // This allows markers to flash again on next playback
                    let count = self.triggeredMarkers.count
                    self.triggeredMarkers.removeAll()
                    if count > 0 {
                        print("üõë [Detection] Playback stopped, reset \(count) triggered marker(s)")
                    }
                } else {
                    // Playback started
                    let startFrame = Int(round(self.currentTime * Double(self.fps)))
                    print("‚ñ∂Ô∏è [Detection] Playback started at frame \(startFrame)")
                }
            }
            .store(in: &cancellables)

        // MARK: - Marker Crossing Detection
        // ‚úÖ STATE FLAGS PATTERN: Industry-standard approach for marker detection
        // Each marker tracks whether it has been triggered in the current playback session
        $currentTime
            .sink { [weak self] newTime in
                guard let self = self else { return }

                let currentFrame = Int(round(newTime * Double(self.fps)))
                
                // Handle backward movement (rewind/seek) - reset triggered state for passed markers
                if currentFrame < self.previousFrame {
                    // Clear triggered flags for markers we're rewinding past
                    let rewindedMarkers = self.markers.filter { marker in
                        let markerFrame = Int(round(marker.timeSeconds * Double(self.fps)))
                        return currentFrame <= markerFrame && markerFrame <= self.previousFrame
                    }
                    for marker in rewindedMarkers {
                        self.triggeredMarkers.remove(marker.id)
                        print("üîÑ [Detection] Marker '\(marker.name)' reset (rewind from frame \(self.previousFrame) to \(currentFrame))")
                    }
                    self.previousFrame = currentFrame
                    return
                }
                
                // Handle pause/stop - no movement
                guard currentFrame > self.previousFrame else {
                    self.previousFrame = currentFrame
                    return
                }

                // Find all markers crossed in this frame interval
                let crossedMarkers = self.markers.filter { marker in
                    let markerFrame = Int(round(marker.timeSeconds * Double(self.fps)))
                    
                    // Bootstrap case: first update from -1 includes frame 0
                    if self.previousFrame == -1 {
                        return markerFrame <= currentFrame
                    }
                    
                    // Normal case: strict < on left prevents duplicate detections
                    // when AVPlayer sends multiple updates at same frame (N‚ÜíN)
                    return self.previousFrame < markerFrame && markerFrame <= currentFrame
                }
                
                // Trigger flash events only for markers that haven't been triggered yet
                for marker in crossedMarkers {
                    let markerFrame = Int(round(marker.timeSeconds * Double(self.fps)))
                    
                    // Skip if already triggered in this playback session
                    if self.triggeredMarkers.contains(marker.id) {
                        print("‚è≠Ô∏è  [Detection] Marker '\(marker.name)' at frame \(markerFrame) SKIPPED (already triggered in this session)")
                        continue
                    }
                    
                    // Mark as triggered
                    self.triggeredMarkers.insert(marker.id)
                    
                    // Send flash event
                    self.flashCounter += 1
                    let event = MarkerFlashEvent(
                        markerID: marker.id,
                        markerName: marker.name,
                        eventID: self.flashCounter,
                        timestamp: Date()
                    )
                    self.markerFlashPublisher.send(event)
                    print("‚ú® [Detection] Marker '\(marker.name)' EVENT SENT #\(self.flashCounter) at frame \(markerFrame) (interval: \(self.previousFrame)‚Üí\(currentFrame))")
                }

                self.previousFrame = currentFrame
            }
            .store(in: &cancellables)
    }
    
    // MARK: - Frame Quantization
    
    /// –ö–≤–∞–Ω—Ç—É–µ—Ç –≤—Ä–µ–º—è –∫ –±–ª–∏–∂–∞–π—à–µ–º—É –∫–∞–¥—Ä—É –Ω–∞ —Ç–∞–π–º–ª–∞–π–Ω–µ
    /// –≠—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è —Ç–æ—á–Ω–æ–π –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Ä–∫–µ—Ä–æ–≤, —Ç–∞–∫ –∫–∞–∫ –º–∞—Ä–∫–µ—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø—Ä–∏–≤—è–∑–∞–Ω—ã –∫ –∫–∞–¥—Ä–∞–º
    private func quantizeToFrame(_ time: Double) -> Double {
        let frameNumber = round(time * Double(fps))
        return frameNumber / Double(fps)
    }
    
    // MARK: - Waveform Cache
    
    private func loadWaveformCache(for audio: TimelineAudio, documentURL: URL) {
        let cacheKey = "\(timelineID.uuidString)_\(audio.id.uuidString)"
        self.waveformCacheKey = cacheKey

        if let cached = WaveformCache.load(cacheKey: cacheKey) {
            // Load all mipmap levels for adaptive rendering
            self.waveformMipmaps = cached.mipmaps
            self.cachedWaveform = cached.mipmaps.first ?? []
            print("‚úÖ Waveform loaded from cache: \(cached.mipmaps.count) mipmap levels")
            for (idx, level) in cached.mipmaps.enumerated() {
                print("   Level \(idx): \(level.count) samples")
            }
            return
        }

        print("üåä No waveform cache found, will generate...")
        Task {
            await generateWaveformCache(audio: audio, documentURL: documentURL, cacheKey: cacheKey)
        }
    }

    private func generateWaveformCache(audio: TimelineAudio, documentURL: URL, cacheKey: String) async {
        print("üåä generateWaveformCache started")
        do {
            let audioURL = documentURL.appendingPathComponent(audio.relativePath)
            print("üåä Audio URL: \(audioURL)")

            let cached = try await WaveformCache.generateAndCache(
                audioURL: audioURL,
                cacheKey: cacheKey
            )
            print("‚úÖ Waveform generated: \(cached.mipmaps.count) mipmap levels")

            await MainActor.run {
                // Store all mipmap levels for adaptive rendering
                self.waveformMipmaps = cached.mipmaps
                self.cachedWaveform = cached.mipmaps.first ?? []
                print("‚úÖ Waveform cached with \(cached.mipmaps.count) mipmap levels:")
                for (idx, level) in cached.mipmaps.enumerated() {
                    print("   Level \(idx): \(level.count) samples")
                }
            }
        } catch {
            print("‚ö†Ô∏è Waveform generation failed:", error)
        }
    }
    
    // MARK: - Audio
    
    func addAudio(
        sourceData: Data,
        originalFileName: String,
        fileExtension: String,
        duration audioDuration: Double
    ) throws {
        print("üéµ addAudio called: \(originalFileName), duration: \(audioDuration)s")

        guard let docURL = repository.documentURL else {
            print("‚ùå documentURL is nil")
            throw NSError(domain: "Timeline", code: 1)
        }

        print("‚úÖ documentURL: \(docURL)")

        let manager = AudioFileManager(documentURL: docURL)
        let fileName = "\(UUID().uuidString).\(fileExtension)"

        print("üéµ Adding audio file: \(fileName)")
        try manager.addAudioFile(sourceData: sourceData, fileName: fileName)
        print("‚úÖ Audio file written")

        let relativePath = "Audio/\(fileName)"
        let newAudio = TimelineAudio(
            relativePath: relativePath,
            originalFileName: originalFileName,
            duration: audioDuration
        )

        print("üéµ Updating timeline audio...")

        if let idx = repository.project.timelines.firstIndex(where: { $0.id == timelineID }) {
            repository.project.timelines[idx].audio = newAudio
            print("‚úÖ Timeline audio updated in repository")
        } else {
            print("‚ùå Timeline not found in repository")
        }

        // Update ViewModel-specific state
        self.duration = audioDuration

        print("üéµ Loading audio into player...")
        let audioURL = docURL.appendingPathComponent(newAudio.relativePath)
        audioPlayer.load(url: audioURL)
        print("‚úÖ Audio loaded into player: \(audioURL)")

        let cacheKey = "\(timelineID.uuidString)_\(newAudio.id.uuidString)"
        self.waveformCacheKey = cacheKey

        print("üéµ Starting waveform generation...")
        Task {
            await generateWaveformCache(audio: newAudio, documentURL: docURL, cacheKey: cacheKey)
            print("‚úÖ Waveform generation task started")
        }
    }
    
    func removeAudio() {
        guard
            let audioFile = audio,
            let docURL = repository.documentURL
        else {
            print("‚ö†Ô∏è Cannot remove audio: audio or documentURL is nil")
            return
        }

        let manager = AudioFileManager(documentURL: docURL)

        do {
            try manager.deleteAudioFile(fileName: audioFile.relativePath)
            print("‚úÖ Audio file deleted: \(audioFile.relativePath)")
        } catch {
            print("‚ö†Ô∏è Failed to delete audio file: \(error.localizedDescription)")
            // Continue with removing audio reference even if file deletion fails
        }

        if let idx = repository.project.timelines.firstIndex(where: { $0.id == timelineID }) {
            repository.project.timelines[idx].audio = nil
            print("‚úÖ Audio reference removed from timeline")
        }

        // Clear ViewModel-specific state
        self.duration = 0
        self.currentTime = 0
        self.cachedWaveform = []
        self.waveformMipmaps = []
        self.waveformCacheKey = nil

        audioPlayer.stop()
        print("‚úÖ Audio player stopped and state cleared")
    }
    
    // MARK: - Playback
    
    func togglePlayPause() {
        audioPlayer.togglePlayPause()
    }
    
    func seek(to time: Double) {
        let clamped = max(0, min(time, duration))
        audioPlayer.seek(by: clamped - currentTime)
    }
    
    func seekBackward() {
        audioPlayer.seek(by: -5)
    }
    
    func seekForward() {
        audioPlayer.seek(by: 5)
    }
    
    // MARK: - Markers
    
    func addMarkerAtCurrentTime() {
        // ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ö–≤–∞–Ω—Ç—É–µ–º –≤—Ä–µ–º—è –∫ –±–ª–∏–∂–∞–π—à–µ–º—É –∫–∞–¥—Ä—É
        // –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –º–∞—Ä–∫–µ—Ä—ã –≤—Å–µ–≥–¥–∞ –ø—Ä–∏–≤—è–∑–∞–Ω—ã –∫ –∫–∞–¥—Ä–∞–º —Ç–∞–π–º–ª–∞–π–Ω–∞
        let quantizedTime = quantizeToFrame(currentTime)
        
        let marker = TimelineMarker(
            timeSeconds: quantizedTime,
            name: "Marker \(markers.count + 1)"
        )
        repository.addMarker(timelineID: timelineID, marker: marker)
        
        print("‚úÖ Marker added at frame-aligned time: \(String(format: "%.6f", quantizedTime))s (from \(String(format: "%.6f", currentTime))s)")
    }

    func moveMarker(_ marker: TimelineMarker, to newTime: Double) {
        // ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ö–≤–∞–Ω—Ç—É–µ–º –≤—Ä–µ–º—è –ø—Ä–∏ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–∏ –º–∞—Ä–∫–µ—Ä–∞
        let quantizedTime = quantizeToFrame(newTime)
        
        var updatedMarker = marker
        updatedMarker.timeSeconds = quantizedTime
        repository.updateMarker(timelineID: timelineID, marker: updatedMarker)
        
        print("‚úÖ Marker moved to frame-aligned time: \(String(format: "%.6f", quantizedTime))s (from \(String(format: "%.6f", newTime))s)")
    }

    func renameMarker(_ marker: TimelineMarker, to newName: String) {
        var updatedMarker = marker
        updatedMarker.name = newName
        repository.updateMarker(timelineID: timelineID, marker: updatedMarker)
    }

    func deleteMarker(_ marker: TimelineMarker) {
        repository.removeMarker(timelineID: timelineID, markerID: marker.id)
    }
    
    // MARK: - Timeline

    func renameTimeline(to newName: String) {
        repository.renameTimeline(id: timelineID, newName: newName)
    }
    
    // MARK: - Timecode
    
    func timecode() -> String {
        let totalFrames = Int(currentTime * Double(fps))
        let frames = totalFrames % fps
        let totalSeconds = totalFrames / fps
        let seconds = totalSeconds % 60
        let totalMinutes = totalSeconds / 60
        let minutes = totalMinutes % 60
        let hours = totalMinutes / 60
        
        return String(format: "%02d:%02d:%02d:%02d", hours, minutes, seconds, frames)
    }
}
